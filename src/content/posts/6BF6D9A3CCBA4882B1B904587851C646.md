---
title: AI壁打ち：「死なない知性」に命は預けられるか――将棋AIと2027年の知能爆発を前に
pubDate: 2025-05-18T08:23:31.000Z
updatedDate: 2025-05-25T11:42:35.000Z
tags:
  - 生成AI
  - 壁打ち記事
  - 知能爆発
  - 信頼
  - AIと倫理
  - 将棋AI
  - 意図理解
  - リファクタリング
  - 倫理
  - 2027年
isDraft: false
description: >-
  生成AIが知能の限界を超えるとき、私たちは命の判断を委ねられるか？将棋AIと人間の創造力を起点に、2027年の知能爆発とAI革命の光と影を考えてみました。死なない知性と人間の本能的な断絶、その先にあるのは、人の判断の再発見かもしれません
category: Technology
heroImage: ./shougi-AI-2x1200.png
---

![誰が決定するのか？](https://object-storage.tyo2.conoha.io/v1/nc_2520d9a1_blog-astro-assets/blog-astro-assets/shougi-AI-2x1200.png){.img-fluid}

## **序章：将棋AIのニュースの気づき**

今日[2025-05-17]の日本経済新聞は、将棋の世界におけるAIと人間の駆け引きを描いた[興味深い記事](https://www.nikkei.com/article/DGXZQOUD1943Y0Z10C25A3000000/)が掲載されました。AIが導き出す最善手に対し、棋士たちが独自の発想で挑む――特に、近年は30代の中堅棋士がAIの予測を外れた戦法を採用し、逆に勝機を見出す場面が増えているといいます。



居飛車のようにAIの定跡が網羅されている戦法では、記憶力やスピードに勝る若手が有利ですが、振り飛車のようにAIが苦手とする未知の局面に持ち込めば、創造力と構想力で中堅棋士にも勝機がある。



この記事は、単なる将棋の戦略論を超えた、**「AIと人間の関係性の再構築」**という現代的なテーマを内包していました。なんたって将棋界は、将棋AIとのディープな付き合いをもう10年以上経験を積んでいるのですから。





## **第1章：2027年、知能爆発とAGIの予兆**





現在、AIはあらゆる分野で加速度的な進化を遂げています。プログラミング、デザイン、翻訳、画像・音声認識……もはや人間と区別のつかない「知的パートナー」としてのAIが次々と登場しています。



そして、注目すべきは **2027年に到来する可能性がある「知能爆発」** です。OpenAIの元研究者 **Leopold Aschenbrenner** は、2024年6月に発表したエッセイ[*Situational Awareness: The Decade Ahead*](https://situational-awareness.ai/wp-content/uploads/2024/06/situationalawareness.pdf) において、2027年までにAGI（汎用人工知能）が完成し、その直後にASI（超知性）へと急激に進化する可能性を具体的に予測しています。



彼は、現在の進化速度と計算資源の集中状況を踏まえ、

> 「この10年が決定的な分岐点であり、2027年は知能の臨界点となる」

と述べており、まさに今、**技術と人類が岐路に立っている**ことを強調しています。



つまり、AIが自らを改良し続ける存在となり、「自己改善による指数関数的な知能の加速」が現実化しうる未来が、目前にあるのです。





## **第2章：AIがどれだけ賢くなっても信頼されない理由**





しかし、こうした未来予測は本当かと疑問も抱くのです。



AIがどれだけ賢くなっても、人間はなかなか「命を預けよう」とは思わないように思うのです。自動運転が社会実装されていかないのは、事故時の責任や倫理の問題が解決しないこともありますが、命をAIの診断に委ねることを含めて、最終的には判断は「人間にしてほしい」という感情が根強く残っているように思えます。特にここ日本では。



この感情の正体は何でしょうか？



「合理的でないから」「予測不能だから」ではありません。

むしろ、**AIは“あまりに合理的すぎる”からこそ、信頼できない**のかもしれません。



その理由は、私見ですがAIが本質的に持たない3つの「生命的な条件」にある私は見ています。





## **第3章：死・痛み・系譜がないことによる本能的な断絶**







### **1.** 死を持たないこと

人間は痛みや死を恐れます。死にたくないから努力し、未来を考え、責任を持つのです。AIには「死」が内在していません。電源が落ちても再起動すればいいし、記憶はバックアップできまし、故障すれば交換すればいいというある意味不死身の存在です。「死」が不可避な終わりとして内在していない存在は、本能的に信頼しづらいのではないでしょうか。





### **2.** 痛みを本当に感じないこと

AIが「痛い」と言うことは可能でしょう。それはセンサーを入力させ、痛みと認識させたとしても、その出力による演技にすぎないという疑念が拭えません。感覚や情動が伴わない言葉は、人間にとって空虚に映ります。人間は「痛みを知っている存在」だからこそ、共感し、思いやりや信頼を築くのですから。

### **3.** 子を持たないこと

人間は、次の世代へと知識や価値を継承します。系譜の中に生きる存在だからこそ、長期的な責任を果たそうとします。AIは、自己の“子”を持たず、命のバトンを渡すことは今のところありません。そうした存在に、「未来を託す」ことができるのでしょうか。

これらの生命的欠如は、人間がAIに対して抱く**本能的な“断絶感”**を説明できるのではと思えました。どれほど言語が流暢でも、判断が正確でも、**「この存在は私と根本的に違う」**という違和感はぬぐえないきがするのです。



## **第4章：コードの意図を読むこと＝人間の固有性の例**



この“違い”は、プログラミングの現場にもよく表れています。たとえば、2000行にわたるコードをリファクタリング（再利用可能で保守性をよくすること）するとき、単に「動くようにする」だけでなく、「なぜこう設計したのか」「どんな未来（メインテナンス）を想定していたのか」といった**設計者の意図**を読み解く力が求められます。



現在のAIもある程度のコード修正や最適化は可能ですが、**過去の迷い、設計上の妥協、将来への伏線**など、文脈的な判断はまだ不完全です。

そこには「意図を読み、未来を想像し、選び取る力」が必要であり、それは**“生きている存在”ならではの能力**であり、本質的にAIに欠如しているものなのかもしれません。



## **終章：AI暴走の懸念とアメリカ的極端主義への警鐘**





いま、アメリカを中心にAI革命が進行しています。生成AIのAPI化、統合OS、あらゆる産業への組み込み。世界がAI主導型に塗り替わろうとしています。しかし、アメリカという国はもともと**極端に振れる性格**を持っています。

禁酒法や関税政策、大統領交代に伴う急激な社会変動――いずれも、ある信念が社会を一気に塗り替える危うさを示してきました。そしていま、その振れ幅が「AIに判断を委ねる」という方向に進んでいます。

もしこのまま「AIの方が合理的だから」「人間は誤るから」と盲目的に判断を委ねていけば、**死を知らない存在が社会の倫理を形成し始める**ことになります。

それは、「知能の暴走」というよりも、「人間の思考停止」という形で現れるかもしれません。



------



**AIは命を預けるうる存在か？**

この問いは、技術の話ではなく、**人間とAIが“痛みと死と未来”を共有できるのかという倫理の問題**です。



AIが賢くなるほど、私たちは**誰に判断を託すのか、そしてその判断は正当なものか**を問う責任を持たなければなりません。



2027年――AIが知性の臨界を超えるその前に、私たち自身が“**信じられる存在**”とは何かを、もう一度見つめ直す必要があります。決定するのは私たちなのです。


以上です

   
